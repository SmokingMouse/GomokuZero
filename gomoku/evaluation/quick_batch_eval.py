#!/usr/bin/env python3
"""
å¿«é€Ÿæ‰¹é‡æ¨¡å‹è¯„ä¼°
è¯„ä¼°å…³é”®è®­ç»ƒèŠ‚ç‚¹çš„æ¨¡å‹æ€§èƒ½
"""

import torch
from gomoku.gomoku_env import GomokuEnv
from gomoku.zero_mcts import ZeroMCTS
from gomoku.mcts import MCTS, RandomStrategy
from gomoku.policy import ZeroPolicy
import time
import os

def quick_evaluate_model(model_path, num_games=20, zero_iterations=100, mcts_iterations=400):
    """å¿«é€Ÿè¯„ä¼°å•ä¸ªæ¨¡å‹"""
    print(f"è¯„ä¼°ï¼š{os.path.basename(model_path)}")
    
    # åŠ è½½æ¨¡å‹
    policy = ZeroPolicy(board_size=9).to('cpu')
    try:
        policy.load_state_dict(torch.load(model_path, map_location='cpu'))
        policy.eval()
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        return None
    
    zero_wins = 0
    total_time = 0
    
    for game in range(num_games):
        if game % 5 == 0 and game > 0:
            print(f"  è¿›åº¦ï¼š{game}/{num_games}")
        
        env = GomokuEnv(board_size=9)
        zero_player = ZeroMCTS(env.clone(), policy, device='cpu')
        mcts_player = MCTS(env.clone(), strategy=RandomStrategy(), c=1.41)
        
        zero_first = (game % 2 == 0)
        current_player = "zero" if zero_first else "mcts"
        players = {"zero": zero_player, "mcts": mcts_player}
        
        move_count = 0
        start_time = time.time()
        
        while not env._is_terminal() and move_count < 81:
            player = players[current_player]
            if current_player == "zero":
                player.run(iterations=zero_iterations, use_dirichlet=False)
                action, _ = player.select_action_with_temperature(temperature=0, top_k=5)
            else:
                action = player.run(iterations=mcts_iterations)
            
            if action is None:
                break
                
            env.step(action)
            zero_player.update_root(action)
            
            current_player = "mcts" if current_player == "zero" else "zero"
            move_count += 1
        
        end_time = time.time()
        total_time += (end_time - start_time)
        
        # åˆ¤æ–­ç»“æœ
        winner = env.winner
        zero_won = (winner == 1 and zero_first) or (winner == 2 and not zero_first)
        
        if winner == 0:
            pass  # å¹³å±€
        elif zero_won:
            zero_wins += 1
    
    win_rate = zero_wins / num_games
    avg_time = total_time / num_games
    
    print(f"  ç»“æœï¼šèƒœç‡ {win_rate:.1%} ({zero_wins}/{num_games})")
    print(f"  å¹³å‡ç”¨æ—¶ï¼š{avg_time:.2f}ç§’/å±€")
    
    return {
        'model': os.path.basename(model_path),
        'win_rate': win_rate,
        'wins': zero_wins,
        'avg_time': avg_time
    }

def quick_batch_eval():
    """å¿«é€Ÿæ‰¹é‡è¯„ä¼°å…³é”®æ¨¡å‹"""
    print("å¿«é€Ÿæ‰¹é‡æ¨¡å‹è¯„ä¼°")
    print("=" * 50)
    
    # é€‰æ‹©å…³é”®è¯„ä¼°ç‚¹
    key_models = [f'../{elem}' for elem in [
        "models/gomoku_zero_9_pre/policy_step_50000.pth",   # 1ä¸‡æ­¥
        # 'models/gomoku_zero_9_plus_pro_max/policy_step_10000.pth',   # 1ä¸‡æ­¥
        # 'models/gomoku_zero_9_plus_pro_max/policy_step_50000.pth',   # 5ä¸‡æ­¥
        # 'models/gomoku_zero_9_plus_pro_max/policy_step_100000.pth',  # 10ä¸‡æ­¥
        # 'models/gomoku_zero_9_plus_pro_max/policy_step_150000.pth',  # 15ä¸‡æ­¥
        # 'models/gomoku_zero_9_plus_pro_max/policy_step_199000.pth',  # 19.9ä¸‡æ­¥
    ]]
    print(key_models)
    
    results = []
    total_start = time.time()
    
    for i, model_path in enumerate(key_models):
        print(f"\n[{i+1}/{len(key_models)}] ", end="")
        
        if not os.path.exists(model_path):
            print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
            continue
            
        result = quick_evaluate_model(model_path, num_games=20)
        if result:
            results.append(result)
    
    total_end = time.time()
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\n{'='*50}")
    print("è¯„ä¼°å®Œæˆï¼")
    print(f"æ€»ç”¨æ—¶ï¼š{(total_end - total_start)/60:.1f}åˆ†é’Ÿ")
    print(f"{'='*50}")
    
    print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼š")
    print("-" * 50)
    print(f"{'æ¨¡å‹':<25} {'èƒœç‡':<8} {'èƒœåœº':<8} {'å¹³å‡ç”¨æ—¶'}")
    print("-" * 50)
    
    for result in results:
        step = result['model'].split('step_')[1].split('.pth')[0]
        print(f"Step {step:<20} {result['win_rate']:.1%}{'':<4} {result['wins']:<8} {result['avg_time']:.2f}ç§’")
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    if results:
        best_model = max(results, key=lambda x: x['win_rate'])
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼š{best_model['model']}")
        print(f"   èƒœç‡ï¼š{best_model['win_rate']:.1%}")
        
        # è¶‹åŠ¿åˆ†æ
        win_rates = [r['win_rate'] for r in results]
        if len(win_rates) >= 3:
            early_avg = sum(win_rates[:2]) / 2
            late_avg = sum(win_rates[-2:]) / 2
            
            print(f"\nğŸ“ˆ è®­ç»ƒè¶‹åŠ¿ï¼š")
            print(f"   æ—©æœŸå¹³å‡èƒœç‡ï¼š{early_avg:.1%}")
            print(f"   åæœŸå¹³å‡èƒœç‡ï¼š{late_avg:.1%}")
            
            if late_avg > early_avg:
                print("   âœ… æ¨¡å‹æ€§èƒ½éšè®­ç»ƒæå‡")
            else:
                print("   âš ï¸ æ€§èƒ½æå‡æœ‰é™")
    
    return results

if __name__ == "__main__":
    quick_batch_eval()